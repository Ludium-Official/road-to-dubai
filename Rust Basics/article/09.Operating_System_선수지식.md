# Operating System Basics for Asynchronous/Parallel Programming

## Learning Objectives

- Understand the basic concepts of operatino system and its relationship with async/parallel programing of Rust
- Learn the differences between Processes and Threads and their usage in Rust
- Learn about context switching and scheduling and their relationship with Rust's asynchronous execution
- Learn about synchronization techniques and their relationship with Rust's concurrency primitives 
- Learn about memory management and virtual memory and their relationship with Rust's memory management Safety
- Compare I/O models and Rust's asynchronous I/O implementation methods
- Learn how to apply operating system concepts in actual Rust code

## Operating Systems and Rust's Asynchronous/Parallel Programming


<img width="802" alt="image" src="https://github.com/user-attachments/assets/3214f8f5-a746-4b38-88fb-9ec000985a37">

Operating system is a system software that primarily manages computer hardware and provides various functions to applications. Understanding operating systems is necessary to utilize Rust's asynchronous and parallel capabilities in full effectivness and also to understand Rust's advantages. It manages hardware resources as shown in the figure above.

## Two CPU Modes

<img width="775" alt="image" src="https://github.com/user-attachments/assets/f1d10765-05a2-497d-b967-2e0483a9165b">

CPU has two modes: User Mode & Kernel Mode. Mode is set up by status bit in protected register

### User Mode
User mode is basically where normal applications are run. 
In user mode accessing hardware resources is prohibited due to limited access and cannot modify important parts of the system

Examples: Web browsers, word processors, and other general application execution, user-level library function calls

### Kernel Mode
Kernel Mode is where operation system code(kernel) is runs (a.k.a called Supervisor Mode or System Mode).

In Kernel mode every all hardware and CPU instructions are accessible (through kernel program execution!) 

Examples: Memory management, process scheduling, file system management

If a User Program is in need of certain jobs which requires resources that are accessible through kernel ex) I/O, then mode switching is required. 

This mode change occurs in the following situations: 

(1) Hardware Interrupt - For example, Timeout interrupt

(2) Software interrupt (exception) - Error occurrence

(3) System call - When requested by user

To summarize, assuming I'm a process, (1) and (2) are handling of processes that are unrelated to me, and (3) is a kernel privilege request that I (the user) am requesting. However, 2 and 3 cannot be strictly separated.

Example
<img width="693" alt="image" src="https://github.com/user-attachments/assets/12deab84-0bf0-4992-8ed0-cad649e87f8a">

## OS Roles 

(1) User Service
provides various user-friendly services.

- Loading Program in a memory + Program Execution  
- I/O Operations
- File system File reading, writing
- Communications
  Communication between physically different systems via network, or between processes within one computer

- Error Detection & Handling
  
(2) Resource Allocation
  Allocates resources for Multiple Users (e.g., server systems) or Multiple tasks (multiple processes)

(3) Accounting
  Can measure usage for users and resources
(4) Protection
  Ensures safety of system control/access

## System Call 
Running Program(User Program)and OS interacts through system call api(application programming interface)

<img width="690" alt="image" src="https://github.com/user-attachments/assets/09d82c62-9823-4369-865c-489e0ceda79f">

This interface (abstraction) makes it easier for user program developers to develop without knowing OS functions in detail (in fact, since syscall requires knowledge of kernel functions, programming language libraries wrap syscall to provide user libraries), and improves system security and portability.

POSIX API is an example of this. POSIX API abstracts syscalls. 
![image](https://github.com/user-attachments/assets/405b3ce9-2430-4b63-9a70-1ef53214d410)


## Process

A process can be understood as the unit by which the OS manages programs. The definition of a process is as follows:

<img width="406" alt="image" src="https://github.com/user-attachments/assets/3b02f5df-d7aa-4626-8842-d1104e0691ae">  

A process consists of the following elements:

프로세스는 다음 요소로 구성되어있다.
1. images
   -Code: 기계어
   -Data: 변수
   -Stack: States for function calls
   -Heap: dynamic memory

   ![image](https://github.com/user-attachments/assets/1875bc5b-b822-420a-977d-14c71bfa74c1)

  
2. Process context
   -Program Context: data registers, pc, sp ... 
   -Kernel Context: pid, gid, open files, paging tables ... 

그래서 이런 정보들 다 모아가지고, essential kernel data structure인 PCB를 설계한다. 
PCB의 element는 앞서 말한 Images, Process Context를 이용해서 설계한다. 즉, 프로세스를 관리하기 위한 추상 데이터 구조를 설계한 것이다. 다음은 실제 리눅스 커널에서 쓰이는 PCB이다. 

![image](https://github.com/user-attachments/assets/30cde532-ec60-4fdb-a69a-40f92a1ffc77)

어렵게 생각할 필요 없고, 모든 소프트웨어는 데이터 구조를 설계하고 그 데이터 구조를 잘 바꾸는 일 밖에 할 것이 없다. 운영체제도 똑같은 소프트웨어이므로, PCB라는 데이터 구조를 설계한 뒤, 그것을 통해 추상화된 프로세스들을 관리한다. 결국 Stored Program Concept에 의헤 Kernel도 Main memory에 적재되어 똑같이 움직인다. 

PCB말고도 Kernel이 운용하는 자료구조는 다음과 같이 더 있다.
- Memory data structures
  프로세스에 대한 메모리 할당, 프로세스에 대한 디스크의 할당, 가상 메모리에 대한 info .. 
- I/O data structures
  I/O device의 가능성, I/O operation의 상태, I/O transfer에 대한 source 혹은 destination이 되는 main memory address
- File data structures
  Current states of file, 파일의 디스크 상 주소 

프로세스의 생명주기 관리는 다음과 같은 다이어그램 처럼 이루어진다.
![image](https://github.com/user-attachments/assets/a88308df-af19-4b10-9221-dbe936b1c383)

이 외에도 OS는 프로세스에 대해서
- 멀티 프로그래밍 Degree
- CPU 할당
- swap Out/in
등에 대한 스케줄링을 실행한다.

### Process switching vs Mode switching
process swithcing은 mode switching에 비해 현저히 적게 일어나지만, process switching은 process context를 저장/불러오기 하는 등의 오버헤드가 발생한다. 
<img width="421" alt="image" src="https://github.com/user-attachments/assets/b8ce8d77-be06-4ffd-a4df-dd6dc6ed472d">


### Process Managing
Process는 creation, exit, 자원 공유 등의 여러가지 생로병사를 가지고 있다.
내 개인적인 생각으로는, 관리(뭐든!)를 하기 위한 가장 좋은 자료구조는 tree 구조라고 생각한다. 왜냐하면, 의존 관계가 명확하고, 
그로 인한 각각 인스턴스의 관할 하의 전체적이면서도 세부적인 관리가 가능하기 때문이다. 그래서 역사책에 중앙집권 체제의 그래프를 보면 보통 트리 구조이다.(ㅋㅋ)
![image](https://github.com/user-attachments/assets/64b2cdfc-ed58-4dc3-8f2d-6a1b4f0854ff)

잡소리 그만 하고, 프로세스는 다음과 같은 형태로 생성되고 관리된다. 즉, 부모 프로세스 및 자식 프로세스의 관계가 존재한다. 
![image](https://github.com/user-attachments/assets/320bf2e9-7e72-4de5-8f33-bf3c5a87c72b)



## Excution of OS

아까도 말했듯이, Stored Program Concept에 의하면 OS도 프로그램 중 하나이며, OS도 프로세스로 올라갈 것이다. 즉, `OS is just subject for Scheduling`.

그렇다면, OS는 누가 controll하는가?
-> OS 디자인에 따라 다르다. 

Non-Process Kernel의 경우 process로서 실행되지 않는다. 
<img width="533" alt="image" src="https://github.com/user-attachments/assets/48381f9d-1a8a-44f6-b2b4-c17a108ff615">


User Process안에 Kernel이 들어있는 경우, Switching을 Process 밖에 있는 PSF에게 스위칭을 위임한다.
<img width="550" alt="image" src="https://github.com/user-attachments/assets/43c3e9e7-fdff-4d2d-8e3e-d4b8746005bb">

이는 완전 독립된 OS Process를 가정한다. 이 경우, 또한 Process 밖에 있는 PSF에게 위임한다. 이 모델은 멀티 프로세서 환경에 적합하다고 할 수 있다. 
<img width="587" alt="image" src="https://github.com/user-attachments/assets/ca31dca8-0a28-4bb1-9def-97b0c884c1d8">

## Multithreading
- process model의 트리 위계 구조를 통해 Web server의 여러 클라이언트의 요청을 동시에 처리하기엔 부하가 너무 크다.
- Traditional process는 cpu를 동시에 하나밖에 쓸 수 없어서 멀티 프로세서 아키텍처의 장점을 충분히 활용할 수가 없었다. 물론 멀티 프로세싱을 할 수는 있었지만, single process에 multiple processor을 할당할 수가 없었다는 소리. 

따라서 Multiple Threads Model이 제기되었다.
- Thread는 image와 context를 다 가지고 있는 Process와 달리, sp, pc와 local variable, return register을 트래킹 하기 위한 Stack 정도로만 구성되어있다. 간단히 말하면 Thread = Stack + Thread Context
- Thread들끼리는 코드와 대부분의 data를 공유한다. Context도 공유한다.

Modern Process 모델은 다음과 같이 구성되어있다.
<img width="802" alt="image" src="https://github.com/user-attachments/assets/d863aef8-1efb-4259-9cc0-1c8a59b641bd">

논리적 구조로 보면, Process는 트리 형태, Thread는 병렬 관계로 관리한다. 

<img width="661" alt="image" src="https://github.com/user-attachments/assets/dd7123d3-e9f3-4de4-93a7-3919edb63bed">

Threads와 Processes의 공통점:
- 고유의 logical flow가 있다.
- 각각 다 스케줄링 된다.

차이점:
- Thread들 끼리는 코드와 데이터를 공유한다.
- Thread들은 트리 위계 구조가 없고, 경량화 되어있으므로 process보다 쉽게 생성된다.
- IPC와 다르게, Thread들 끼리는 주소 공간과 메모리를 공유하므로, kernel 개입 없이 커뮤니케이션이 가능하다.

이를 통해, 단일 프로세스를 구성하는 Thread들에 CPU가 하나씩 할당되어 단일 프로세스에 대한 병렬 처리가 가능해졌다. 

### User-Level Thread vs Kernel-Level Thread

#### User-Level Thread
Thread 관리가 user-level threads library로 이루어진다. 그리고 kernel은 해당 thread들의 존재를 모른다.
- 장점
  경량화되어있음(user space에서 모든 생명주기가 일어나므로 kernel이 개입할 필요가 없음)
  Context switching이 kernel 모드로의 전환 없이 이루어져 오버헤드가 적다.
- 단점
  어떤 Thread의 I/O라고 해당 전체 프로세스를 블로킹한다.
  멀티 프로세서의 이점을 얻을 수 없음 
![image](https://github.com/user-attachments/assets/a3c7c0c3-111e-47dc-8c69-2f2188eca39b)

#### Kernel-Level Thread
OS가 관리하는 Threads
- 장점
  kernel이 인지하므로, 멀티 프로세서의 이점을 가질 수 있다.
  하나가 I/O한다고 해서 모두 블로킹 되지 않는다.
- 단점
  라이브러리의 Thread 생성이 Kernel Thread 생성을 야기한다. 

![image](https://github.com/user-attachments/assets/5b0336f2-5182-4a4e-95af-04039ae022ee)

적절히 섞어쓴게 M:N Thread 모델인데, 대표적으로는 Go언어의 고루틴이 있다.
https://medium.com/@rezauditore/introducing-m-n-hybrid-threading-in-go-unveiling-the-power-of-goroutines-8f2bd31abc84

하지만, Rust는 Ownership system을 바탕으로 인한 편리한 동시성 문제 해결로 인해 고성능 병렬성을 쉽게 구현할 수 있다. 따라서 1:1 Thread 모델을 채택한다. 
https://doc.rust-kr.org/ch16-01-threads.html

## Multiprocessor scheduling

멀티프로세서 스케줄링은 여러 개의 CPU를 효율적으로 활용하기 위한 스케줄링 방식이다. 단일 프로세서 스케줄링과 비교했을 때 몇 가지 새로운 문제와 고려사항이 발생한다.

멀티프로세서 스케줄링에서 고려해야 할 주요 사항은 다음과 같다:

1. Cache affinity
   - 프로세스를 이전에 실행되었던 CPU에서 계속 실행하면 캐시 히트율을 높일 수 있다. 
   - 프로세스가 특정 CPU에서 실행될 때 해당 CPU의 캐시와 TLB에 상당한 상태 정보가 쌓이게 된다.
   - 다음에 그 프로세스를 실행할 때 같은 CPU에서 실행하면 이미 캐시에 있는 상태를 재사용할 수 있어 성능이 향상된다.

2. Load balancing
   - 모든 CPU에 골고루 작업을 분배해야 한다.
   - CPU 간에 작업량 차이가 크면 일부 CPU는 과부하 상태가 되고 다른 CPU는 유휴 상태가 되어 전체적인 성능이 저하된다.

3. 병렬성(Parallelism)
   - 병렬 실행 가능한 작업들을 서로 다른 CPU에 할당해야 한다.
   - 멀티스레드 애플리케이션의 경우 여러 스레드를 동시에 실행할 수 있도록 스케줄링해야 한다.

4. 동기화(Synchronization)
   - 여러 CPU에서 공유 데이터에 접근할 때 동기화 문제가 발생할 수 있다.
   - 락(lock)과 같은 상호 배제 기법을 사용해 데이터의 일관성을 보장해야 한다.

5. Scalability
   - CPU 수가 증가해도 스케줄러의 성능이 크게 저하되지 않아야 한다.
   - 락 경합 등으로 인한 오버헤드를 최소화해야 한다.

멀티프로세서 스케줄링의 알고리즘은 다음과 같다:

1. SQMS: Single-Queue Multiprocessor Scheduling
   - 하나의 중앙 큐를 사용해 모든 작업을 관리한다.
   - 장점:
     - 구현이 간단하다. 기존의 단일 CPU 스케줄러를 쉽게 확장할 수 있다.
     - 로드 밸런싱이 자연스럽게 이루어진다.
   - 단점:
     - 확장성 문제: CPU 수가 증가하면 중앙 큐에 대한 락 경합이 심해져 성능이 저하된다.
     - 캐시 친화성 문제: 프로세스가 여러 CPU를 옮겨 다니면서 캐시 효율성이 떨어진다.

   SQMS의 예:
   ```
   Queue: A B C D E NULL

   CPU 3: D C B A E ... (repeat) ...
   CPU 2: C B A E D ... (repeat) ...
   CPU 1: B A E D C ... (repeat) ...
   CPU 0: A E D C B ... (repeat) ...
   ```

   이 경우 각 작업이 CPU 간에 계속 이동하므로 캐시 친화성이 떨어진다.

2. MQMS: Multi-Queue Multiprocessor Scheduling
   - CPU마다 별도의 큐를 사용한다.
   - 장점:
     - 확장성이 좋다. CPU 수가 증가해도 큐 간 경합이 적다.
     - 캐시 친화성이 좋다. 작업이 같은 CPU에 머물러 캐시를 효과적으로 사용할 수 있다.
   - 단점:
     - 로드 밸런싱 문제가 발생할 수 있다. 큐 간 작업량 차이가 생길 수 있다.
     - 구현이 더 복잡하다.

   MQMS의 예:
   ```
   Q0: A C    Q1: B D

   CPU 0: A A C C A A C C ...
   CPU 1: B B D D B B D D ...
   ```

   이 경우 각 작업이 같은 CPU에 머물러 캐시 친화성은 좋지만, 작업 C가 끝나면 로드 불균형이 발생할 수 있다.

3. Work stealing
   - MQMS의 로드 밸런싱 문제를 해결하기 위한 기법이다.
   - 한 CPU의 큐가 비면 다른 CPU의 큐에서 작업을 가져온다.
   - 주기적으로 다른 큐의 상태를 확인하고 필요시 작업을 이동시킨다.
   - 장점:
     - MQMS의 장점을 유지하면서 로드 밸런싱을 개선할 수 있다.
   - 단점:
     - 다른 큐를 확인하는 빈도 설정이 중요하다. 너무 자주 확인하면 오버헤드가 크고, 너무 적게 확인하면 불균형이 오래 지속될 수 있다.

Linux에서는 다음과 같은 멀티프로세서 스케줄러들이 사용된다.

1. O(1) Scheduler
   - 우선순위 기반의 멀티 큐 방식을 사용한다.
   - 각 CPU마다 두 개의 우선순위 큐(활성 큐와 만료 큐)를 사용한다.
   - 상수 시간(O(1))에 스케줄링 결정을 내릴 수 있다.

2. Completely Fair Scheduler (CFS)
   - 비례 공정 스케줄링 방식의 멀티 큐를 사용한다.
   - 레드-블랙 트리를 사용해 실행 시간이 가장 적은 프로세스를 빠르게 선택한다.
   - 각 프로세스에 가중치를 부여해 CPU 시간을 공정하게 분배한다.

3. BF Scheduler (BFS)
   - 단일 큐 방식을 사용한다.
   - EEVDF(Earliest Eligible Virtual Deadline First) 알고리즘을 기반으로 한다.
   - 확장성은 떨어지지만 반응성이 좋고 구현이 간단하다.


## Synchronization
Multithreading, CPU scheduling을 잘 이해했다. 근데 Thread들 사이에 데이터 공유를 저런 식으로 하면 뭔가 문제가 있지 않을까? 

<img width="697" alt="image" src="https://github.com/user-attachments/assets/67add7ec-dd1c-479d-99b8-07abe0fb2e62">

이는 동시성 문제라고 한다. 즉,2개 이상의 Thread들이 아무런 동기화 없이 리소스를 공유하는 것이 문제이다. 
따라서, 동기화 메커니즘이 필요하다. 

어떤 자원을 공유할까? 
- Between processes
  Shard memory objects, files . .. 
- Between threads
  Global variables on static data segment
  dynamic objects on heap

### Critical Sections
- Shared data가 접근되는 영역을 의미한다.

- Critical Sections에서는 한 process가 해당 영역에서 실행될 떄, 다른 process가 접근하는 것을 허용하면 안된다.

Critical Section에서는, Mutual Exclusion(한 process의 동작만 보장되어야한다.) , Bounded Waiting(다른  process의 입장이 무제한 연기되면 안된다.), Progress(진행중인 process가 아무도 없을 때, 다른 process들의 접근이 연기되면 안된다.) 를 충족하는 solution이 필요하다. 

#### Structure
repeat
`entry section`
  critical section
`exit section`
  remainder section
until false;


해당 솔루션에는 `Lock`, `Semaphore`, `Monitor`등이 있다. 차례로 알아보자.

### Locks(low-level synchronization primitive)
두가지 operation을 제공하는 동기화 메커니즘이다.
`acquire()/lock()` and `release()/unlock()`.
Critical Section에 진입 전에 lock()을 요청하고, 나와서는 unlock()을 한다. 

이 방식은 Peterson's algorithm, Atomic 연산 보장, critical section 중에 context switching을 요청하는 시스템 interrupt 방지 등으로 인해서 구현된다.  
그리고 보통 `spinlock`을 통해서 진입 전에 process는 무한 루프를 돌며 대기해야한다. 

### Semaphore
spin lock처럼 busy waiting을 할 필요없이 process 연관 큐를 가진 채로 거기다가 재우고 깨운다.

```rust
 wait(S) {
     S--;
     if S < 0
         // 이 프로세스를 재움 큐에 추가 (잠 듦)
 }

 signal(S) {
     S++;
     if S <= 0
         // 재움 큐로부터 프로세스를 제거 (깨어남)
 }
```

하지만, 이 Wait과 Signal 연산에 대해서 또 동기화 문제가 발생한다. 따라서 또 다시 critical section이 발생하는데, 아주 작으므로 해당 critical section에 대해서는 좀 더 정교한, 하드웨어 솔루션으로 접근이 가능하다. 
Binary Semaphore를 mutex라고 부른다. 

Semaphore는 좋은 방법이지만, 데드락을 발생시킬 수 있다는 문제점이 있다.

#### 철학자 문제 (Dining Philosophers Problem)
철학자 문제는 동시성 문제를 설명하는 유명한 예시다. 
문제의 설정은 다음과 같다:
5명의 철학자가 원형 테이블에 앉아 있다.
각 철학자 사이에 포크가 하나씩 있다 (총 5개의 포크).
철학자는 생각하거나 먹는 두 가지 행동만 한다.
먹기 위해서는 양쪽의 포크 두 개를 모두 사용해야한다.

![출처: 나무위키](https://github.com/user-attachments/assets/b0dda31f-3f17-4743-8580-86e15536bbc0)


이 문제에서 데드락이 발생할 수 있는 상황은 다음과 같다:

모든 철학자가 동시에 왼쪽 포크를 집는다.
각 철학자는 오른쪽 포크를 기다리지만, 모든 포크가 사용 중이므로 영원히 기다리게 된다.
물론, 데드락의 4가지 조건 중 하나씩 깨면서 데드락을 해결하는 해결책이 존재한다! 

데드락의 4가지 조건
- Mutual Exclusion
  한번의 하나의 process만 resource를 이용할 수 있다
- Hold and Wait
  자원을 하나라도 가지고 있는 process가 다른 자원을 받기 위해 기다리는 상황 
- No Preemption
  자원을 자발적으로 내려놓을 때까지 기다려야한다.(선점이 불가) 
- Circular Wait
  resource 할당 그래프에 cycle이 있다 

해결책은 알아서 찾아보도록 하자.

## Ownership System과 동기화 문제 
런타임에 발생하는 문제까지 컴파일러가 다 잡을 수는 없다. 하지만, Rust에서 컴파일러 수준에서의 데이터 경합은 정의되지 않은 동작으로, 컴파일 타임에 완전히 방지할 수 있다. 
하지만 이는 Rust의 가장 강력한 특징 중 하나로, 멀티스레딩 프로그래밍을 훨씬 안전하게 만든다. 
다만, 앞서 언급했듯이 런타임에서 발생하는 데드락이나 라이브락과 같은 다른 종류의 동시성 문제는 여전히 발생할 수 있으므로, 이에 대한 주의는 여전히 필요하다.












